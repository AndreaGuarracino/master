{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/didier/anaconda3/envs/c19biohack_ml/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/didier/anaconda3/envs/c19biohack_ml/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n",
      "/home/didier/anaconda3/envs/c19biohack_ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/didier/anaconda3/envs/c19biohack_ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/didier/anaconda3/envs/c19biohack_ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/didier/anaconda3/envs/c19biohack_ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/didier/anaconda3/envs/c19biohack_ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/didier/anaconda3/envs/c19biohack_ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from eli5 import show_weights, show_prediction\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "#custom\n",
    "from helper import DataProcessing\n",
    "from ml_metrics import evaluate_model, multiclass_logloss\n",
    "from plotting import plot_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set K-mer length here\n",
    "kmer_list = range(3,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-means clustering\n",
    "def run_kmeans(k):\n",
    "    class_dict = dict(zip(range(k), [f'cluster_{i}' for i in range(k)]))\n",
    "    kmeans = MiniBatchKMeans(n_clusters=k,verbose=0, batch_size=100,random_state=101)\n",
    "    ytrain = kmeans.fit_predict(xtrain_ctv)\n",
    "    ytest = kmeans.fit_predict(xtest_ctv)\n",
    "    return ytrain, ytest, class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orf1 = DataProcessing('coronavirus_orf1ab.fasta', 'coronavirus_orf1ab_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 27s, sys: 7.92 s, total: 16min 35s\n",
      "Wall time: 14min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(seed = 101)\n",
    "loss_dict_k_4 = {}\n",
    "for kmer in kmer_list:\n",
    "    amino_df = orf1.get_amino_df(kmer)\n",
    "#     print(amino_df.shape,\"original shape\")\n",
    "\n",
    "    # get rid of duplicates\n",
    "    amino_df.drop_duplicates(subset='Accession', keep=False, inplace=True)\n",
    "#     print(amino_df.shape,\"filtered shape\")\n",
    "    mask = np.random.rand(len(amino_df)) < 0.8\n",
    "    train_df = amino_df[mask]\n",
    "    test_df = amino_df[~mask]\n",
    "    xtrain = train_df['seq_offset_0'].values\n",
    "    xtest = test_df['seq_offset_0'].values\n",
    "#     print(f'Size of the test df: {len(test_df)}. Size of the tain df: {len(train_df)}.')\n",
    "    #vectorize\n",
    "    ctv = CountVectorizer(analyzer='char', ngram_range=(kmer, kmer), lowercase=False) # kmer: k-mer length\n",
    "\n",
    "    ctv.fit(list(xtrain)+list(xtest))\n",
    "    xtrain_ctv = ctv.transform(xtrain)\n",
    "    xtest_ctv = ctv.transform(xtest)\n",
    "    ytrain, ytest, class_dict = run_kmeans(4)\n",
    "    #fit logistic regression on CountVectorizer\n",
    "    \n",
    "    clf = LogisticRegression(C=1.0, max_iter=4000,random_state=101 , n_jobs=-1)\n",
    "    clf.fit(xtrain_ctv, ytrain)\n",
    "    predictions = clf.predict_proba(xtest_ctv)\n",
    "    loss_dict_k_4[\"%i kmer\"%kmer]= {\"logloss\":multiclass_logloss(ytest, predictions),\n",
    "                      \"test set size\":test_df.shape[0] , \n",
    "                      \"train set size\":train_df.shape[0] }\n",
    "#     print (\"************ kmer = {} *********\".format(kmer))\n",
    "#     print (multiclass_logloss(ytest, predictions))\n",
    "#     evaluate_model(predictions, ytest, class_dict)\n",
    "#     amino_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 36s, sys: 6.79 s, total: 11min 43s\n",
      "Wall time: 10min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(seed = 101)\n",
    "loss_dict_k_5 = {}\n",
    "for kmer in kmer_list:\n",
    "    amino_df = orf1.get_amino_df(kmer)\n",
    "#     print(amino_df.shape,\"original shape\")\n",
    "\n",
    "    # get rid of duplicates\n",
    "    amino_df.drop_duplicates(subset='Accession', keep=False, inplace=True)\n",
    "#     print(amino_df.shape,\"filtered shape\")\n",
    "    mask = np.random.rand(len(amino_df)) < 0.8\n",
    "    train_df = amino_df[mask]\n",
    "    test_df = amino_df[~mask]\n",
    "    xtrain = train_df['seq_offset_0'].values\n",
    "    xtest = test_df['seq_offset_0'].values\n",
    "#     print(f'Size of the test df: {len(test_df)}. Size of the tain df: {len(train_df)}.')\n",
    "    #vectorize\n",
    "    ctv = CountVectorizer(analyzer='char', ngram_range=(kmer, kmer), lowercase=False) # kmer: k-mer length\n",
    "\n",
    "    ctv.fit(list(xtrain)+list(xtest))\n",
    "    xtrain_ctv = ctv.transform(xtrain)\n",
    "    xtest_ctv = ctv.transform(xtest)\n",
    "    ytrain, ytest, class_dict = run_kmeans(5)\n",
    "    #fit logistic regression on CountVectorizer\n",
    "    \n",
    "    clf = LogisticRegression(C=1.0, max_iter=4000,random_state=101 , n_jobs=-1)\n",
    "    clf.fit(xtrain_ctv, ytrain)\n",
    "    predictions = clf.predict_proba(xtest_ctv)\n",
    "    loss_dict_k_5[\"%i kmer\"%kmer]= {\"logloss\":multiclass_logloss(ytest, predictions),\n",
    "                      \"test set size\":test_df.shape[0] , \n",
    "                      \"train set size\":train_df.shape[0] }\n",
    "#     print (\"************ kmer = {} *********\".format(kmer))\n",
    "#     print (multiclass_logloss(ytest, predictions))\n",
    "#     evaluate_model(predictions, ytest, class_dict)\n",
    "#     amino_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4K = pd.DataFrame.from_dict(loss_dict_k_4).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5K = pd.DataFrame.from_dict (loss_dict_k_5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logloss_k4</th>\n",
       "      <th>test set size_k4</th>\n",
       "      <th>train set size_k4</th>\n",
       "      <th>logloss_k5</th>\n",
       "      <th>test set size_k5</th>\n",
       "      <th>train set size_k5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3 kmer</th>\n",
       "      <td>13.404110</td>\n",
       "      <td>457.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>5.268189</td>\n",
       "      <td>457.0</td>\n",
       "      <td>1927.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 kmer</th>\n",
       "      <td>5.584802</td>\n",
       "      <td>511.0</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>3.821062</td>\n",
       "      <td>511.0</td>\n",
       "      <td>1873.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 kmer</th>\n",
       "      <td>10.268704</td>\n",
       "      <td>475.0</td>\n",
       "      <td>1909.0</td>\n",
       "      <td>8.464424</td>\n",
       "      <td>475.0</td>\n",
       "      <td>1909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 kmer</th>\n",
       "      <td>9.306516</td>\n",
       "      <td>488.0</td>\n",
       "      <td>1896.0</td>\n",
       "      <td>13.745919</td>\n",
       "      <td>488.0</td>\n",
       "      <td>1896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 kmer</th>\n",
       "      <td>8.984164</td>\n",
       "      <td>437.0</td>\n",
       "      <td>1947.0</td>\n",
       "      <td>14.066950</td>\n",
       "      <td>437.0</td>\n",
       "      <td>1947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 kmer</th>\n",
       "      <td>8.209397</td>\n",
       "      <td>467.0</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>13.805108</td>\n",
       "      <td>467.0</td>\n",
       "      <td>1917.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        logloss_k4  test set size_k4  train set size_k4  logloss_k5  \\\n",
       "3 kmer   13.404110             457.0             1927.0    5.268189   \n",
       "4 kmer    5.584802             511.0             1873.0    3.821062   \n",
       "5 kmer   10.268704             475.0             1909.0    8.464424   \n",
       "6 kmer    9.306516             488.0             1896.0   13.745919   \n",
       "7 kmer    8.984164             437.0             1947.0   14.066950   \n",
       "8 kmer    8.209397             467.0             1917.0   13.805108   \n",
       "\n",
       "        test set size_k5  train set size_k5  \n",
       "3 kmer             457.0             1927.0  \n",
       "4 kmer             511.0             1873.0  \n",
       "5 kmer             475.0             1909.0  \n",
       "6 kmer             488.0             1896.0  \n",
       "7 kmer             437.0             1947.0  \n",
       "8 kmer             467.0             1917.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4K.join(df_5K, lsuffix='_k4', rsuffix='_k5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
